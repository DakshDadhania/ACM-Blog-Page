{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#the-acm-manipal-blog","title":"The ACM Manipal Blog","text":"<p>Keep calm and write code.</p>"},{"location":"#introduction","title":"Introduction","text":"<p>We\u2019ll be putting up helpful and interesting articles written by our members over here to help give beginners an overview about the different areas of interest in coding. This is ACM Manipal Student Chapter a Student Club from Manipal Institute of Technology.</p> <p>Our Page Consists of many Blogs</p>"},{"location":"#navigate-through-the-recent-blogs-","title":"Navigate through the recent blogs -","text":"<ul> <li>How Tech Giants Are Using Your Data</li> <li>Implementing A Deep-Learning Model On A Self-Driving Car</li> <li>Decoding the world of Python libraries</li> <li>Introduction To 3D Computer Graphics</li> <li>Mathematics in Machine Learning</li> <li>C++ tips to get around TLE</li> <li>Navigating Through Graphs</li> <li>Breaking the Ice with Graphs</li> </ul> <p>This Blog will hopefully give you all the resources to start your coding journey and guide you throughout.</p>"},{"location":"#here-are-the-domains-at-acm-manipal-","title":"Here are the Domains at ACM Manipal-","text":"<ul> <li>WebDev</li> <li>AppDev</li> <li>ML and AI</li> <li>Coding</li> <li>Community Service</li> <li>Research</li> <li>Gallery</li> </ul>"},{"location":"blogs/DecodingPythonLib/","title":"DecodingPythonLib","text":"<p>[</p> <p>](https://medium.com/@prernaharshi3403?source=post_page-----58ad4877e042--------------------------------)Prerna MittalFollow</p> <p>Mar 24, 2022</p> <p>\u00b712 min read</p>"},{"location":"blogs/DecodingPythonLib/#decoding-the-world-of-python-libraries","title":"Decoding the world of Python libraries","text":"<p>Introduction</p> <p>Evolution of Artificial Intelligence and Machine Learning in the modern world has led to extensive development in the field of technology enabling categorization of data, fraud detection , recognition of images, or predictions about the future (among other things).</p> <p>Python libraries play a very vital role in fields of Machine Learning, Data Science, Data Visualization, etc. This is a reusable chunk of code that one can include in one\u2019s programs/ projects. It is a collection of modules that can be installed using a package manager like rubygems or npm. Other than pre-compiled codes, a library may contain documentation, configuration data, message templates, classes, and values, etc. This enables smooth, high-efficiency programming, convenient programming.</p> <p>Python Libraries</p> <p>Here\u2019s a list of six widely used and popular libraries for aspiring developers.</p> <ul> <li>SciPy</li> <li>PyTorch</li> <li>Pandas</li> <li>NumPy</li> <li>TernsorFlow</li> <li>MatPlotLib</li> </ul> <p>Each section under every library describes its features and applications in addition to basic information and it\u2019s syntax at a glance. We hope you enjoy exploring these with us.</p> <p>SciPy</p> <p>SciPy is a free and open-source machine learning library used for high level computations by application developers. SciPy has around 19,000 comments on GitHub and an active community of about 600 contributors. It\u2019s extensively used for scientific and technical computations, because it extends NumPy and provides many user-friendly and efficient routines for scientific calculations. However, one can differentiate between the SciPy library and SciPy stack. SciPy library contains modules for optimization, linear algebra, integration, and statistics.</p> <p>Features Of SciPy :</p> <ul> <li>The main feature of the SciPy library is that it is developed using NumPy. Hence the collection of algorithms and functions built on the NumPy extension of Python.</li> <li>In addition, SciPy provides all the efficient numerical routines like optimization, numerical integration, and many others using its specific submodules.</li> <li>All the functions in all submodules of SciPy are well documented.</li> <li>High-level commands for data manipulation and visualization</li> <li>Multidimensional image processing with the SciPy ndimage submodule</li> <li>Includes built-in functions for solving differential equations</li> </ul> <p>Applications of SciPy :</p> <ul> <li>SciPy is a library that uses NumPy for the purpose of solving mathematical functions. SciPy uses NumPy arrays as the basic data structure, and comes with modules for various commonly used tasks in scientific programming.</li> <li>Tasks including linear algebra, integration (calculus), ordinary differential equation solving and signal processing execute easily by SciPy.</li> <li>Multidimensional image operations can be carried out.</li> <li>Solving differential equations and the Fourier transform can be done.</li> <li>Optimization algorithms can be implemented</li> <li>Linear algebra can be performed</li> </ul> <p>Understanding SciPy:</p> <ul> <li>Obtaining information about any function can be done using help(). However this can be performed with or without parameters.</li> </ul> <p>Code -</p> <pre><code>from scipy import clusterhelp(cluster) #with parameterhelp() #without parameter\n</code></pre> <p>To stop execution of this function \u2018quit\u2019 and enter can be used.</p> <ul> <li>scipy.io package provides a number of functions that help you manage files of different formats such as MATLAB files, IDL files, Matrix Market files, etc.</li> </ul> <p>Code -</p> <pre><code>import scipy.io as sio\n</code></pre> <ul> <li>info()- Returns information about the desired function. While source() returns objects written solely in python. Useful information cannot be obtained if objects are written in other languages such as java.</li> </ul> <p>Code -</p> <pre><code>scipy.info(cluster) scipy.source(cluster)\n</code></pre> <ul> <li>Solving exponential and trigonometric functions can be done with SciPy\u2019s special package. Many more operations like integration, double integration etc can also be performed.</li> </ul> <p>Code -</p> <pre><code>from scipy import speciala= special.exp10(3)print(a)b= special.exp2(3)print(b)c= special.sindg(90)print(c)d= special.cosdg(45)print(d)\n</code></pre> <p>Output -</p> <pre><code>1000.08.01.00.7071067811865475\n</code></pre> <p>Optimization of functions</p> <ul> <li>Unconstrained and constrained minimization of multivariate scalar functions i.e minimize (eg. BFGS, Newton Conjugate Gradient, Nelder_mead simplex, etc)</li> <li>Global optimization routines (eg. differential_evolution, dual_annealing, etc)</li> <li>Least-squares minimization and curve fitting (eg. least_squares, curve_fit, etc)</li> <li>Scalar univariate functions minimizers and root finders (eg. minimize_scalar and root_scalar)</li> <li>Multivariate equation system solvers using algorithms such as hybrid Powell, Levenberg-Marquardt.</li> <li>Rosenbrook function (rosen) is a test problem used for gradient-based optimization algorithms. It is defined as follows in SciPy:</li> </ul> <p>Code -</p> <pre><code>import numpy as npfrom scipy.optimisze import rozena= 1.2\\* np.arrange(5)rozen(a)\n</code></pre> <p>Output -</p> <pre><code>7371.0399999999945\n</code></pre> <p>Many more operations like correlation, convolution, etc can be carried out with ease and efficiency using SciPy making it a wonderful library for developers.</p> <p>Website link: https://scipy.org/</p> <p>GitHub link: https://github.com/scipy</p> <p>Pytorch</p> <p>Next in the list of top python libraries for data science is PyTorch, this is a Python-based scientific computing package that uses the power of graphics processing units. Python is a preferred programming language due to its simplicity, productivity and portability. It\u2019s syntax it\u2019s simpler when compared to Java and C++ among others.</p> <p>PyTorch is one of the most commonly used deep learning research platforms built to provide maximum flexibility and speed.</p> <p>Features Of PyTorch:</p> <ul> <li>Hybrid Front-End- A new hybrid front-end provides ease-of-use and flexibility in eager mode, while seamlessly transitioning to graph mode for speed, optimization, and functionality in C++ runtime environments.</li> <li>Distributed Training- Optimize performance in both research and production by taking advantage of native support for asynchronous execution of collective operations and peer-to-peer communication that is accessible from Python and C++.</li> <li>Python First- PyTorch is not a Python binding into a monolithic C++ framework. It\u2019s built to be deeply integrated into Python so it can be used with popular libraries and packages such as Cython and Numba.</li> <li>Libraries And Tools-An active community of researchers and developers have built a rich ecosystem of tools and libraries for extending PyTorch and supporting development in areas from computer vision to reinforcement learning.</li> </ul> <p>Applications of PyTorch:</p> <ul> <li>PyTorch is famous for providing two of the most high-level features</li> <li>It enables tensor computations with strong GPU acceleration support</li> <li>Helps in building deep neural networks on a tape-based autograd system</li> <li>PyTorch is primarily used for applications such as natural language processing.</li> <li>It is primarily developed by Facebook\u2019s artificial-intelligence research group and Uber\u2019s \u201cPyro\u201d software for probabilistic programming is built on it.</li> <li>PyTorch is outperforming TensorFlow in multiple ways and it is gaining a lot of attention in recent days.</li> </ul> <p>Understanding PyTorch:</p> <ul> <li>In PyTorch, every method that ends with an underscore (_) makes changes in-place, meaning, they will modify the underlying variable.</li> <li>Sending tensors( three dimensional arrays) to specified devices including GPU can be done with \u2014 to()</li> <li>In any case if one desires the code back to CPU due to unavailability of GPU cuda.is_available() can be used to find out if a GPU is available at your disposal. It can also be casted to a lower precision(32 bit float) using float(). While type() reveals its location.</li> <li>Autograd is PyTorch\u2019s automatic differentiation package. Partial derivatives, chain rule everything is taken care of. Manual computation gradients can be avoided with the usage of zero_() and backward ().</li> <li>PyTorch can build a dynamic computation graph from every python operation that involves any gradient-computing tensor or it\u2019s dependencies. A tensor is a three dimensional array.</li> <li>torch.no_grad() enables updation of parameters with changing the dynamic computation graph. Regular python operations can now be performed on tensors.</li> <li>PyTorch\u2019s DataLoader can be dictated to use a dataset,the desired mini batch-size or if one would like to shuffle the data. This is like an iterator that can be looped and different mini-batches can be obtained.</li> </ul> <p>_Code (_Creating two tensors of 2 x 3 dimensions each) -</p> <pre><code>import torchx= torch.tensor( \\[ \\[1,2,3\\], \\[4,5,6\\] \\] )y = torch.tensor ( \\[ \\[7,8,9\\], \\[10,11,12\\] \\] )f= 2\\*x + yprint(f)\n</code></pre> <p>Output:</p> <pre><code>( \\[ \\[ 9, 12,15\\],\\[ 18,21,24\\] \\] )\n</code></pre> <p>This was a simple illustration to enable better understanding. In addition to these many more operations can be carried out to develop efficient Deep Learning models using PyTorch.</p> <p>Website link: https://pypi.org/project/pandas/</p> <p>GitHub link: https://github.com/pandas-dev/pandas</p> <p>Pandas</p> <p>As technology enthusiasts we understand how complicated operations can get. Looking forward to simplified execution of data with minimal commands in addition to Re-indexing, Iteration, Sorting, Aggregations, Concatenations and Visualizations the Pandas machine learning library provides all these tools to enable smooth and efficient programming.</p> <p>Created by Wes Mckinney, with around 1700 comments on GitHub and an active community of 1200 contributors this enables high productivity, flexibility in addition to offering extremely responsive data structures.</p> <p>Features of Panda:</p> <ul> <li>Eloquent syntax and rich functionalities that gives one the liberty to manage missing data.</li> <li>It enables creation of your own functions and flexibility to run it across a series of data.</li> <li>High-level abstraction</li> <li>Its high-level data structures and elementary manipulation of simple operations make it a real time- saver.</li> </ul> <p>Applications of Panda:</p> <ul> <li>General data wrangling and data cleaning</li> <li>ETL (extract, transform, load) jobs for data transformation and data storage, as it has excellent support for loading CSV files into its data frame format</li> <li>Used in a variety of academic and commercial areas, including statistics, finance and neuroscience.</li> <li>Time-series-specific functionality, such as date range generation, moving window, linear regression and date shifting.</li> </ul> <p>Understanding Pandas:</p> <p>Data scientists are responsible for processing, cleaning, and validation of integrated data.</p> <p>This can often be a very tiring process. However with Pandas:</p> <pre><code>nba.info ()\n</code></pre> <p>This produces a list of all columns in the dataset and type of data each column contains. Although one can store arbitrary Python in object data type, we are aware of drawbacks. Strange values in an object column can harm Pandas performance and it\u2019s interoperability with other libraries.</p> <ul> <li>Accessing DataFrame elements: The DataFrame consists of a series of objects which can be used to access the elements. The crucial difference is addition of dimension of the DataFrame. Indexing operator for the columns and the access methods .loc and .iloc for rows can be used.</li> <li>For instance-Adjusting the numeric value stored in one column of a data set. Without writing a loop \u201cu-func\u201d can apply changes.</li> </ul> <p>Code -</p> <pre><code>dataFrame\\[\u201ccolName\u201d\\] = dataFrame\\[\u201c colName\u201d\\] / 2\n</code></pre> <ul> <li>Filtration of data can be tedious.</li> </ul> <p>However with Pandas: To find females above the age of 45 following can be implemented with ease.</p> <p>Code -</p> <pre><code>\\# Return rows only where the \u201cfemale\u201d field is True and \u201cage\u201d is &gt; 45adult\\_females = dataFrame\\[ ( dataFrame\\[\u201cfemale\u201d\\] == True) &amp; ( dataFrame\\[\u201cage\u201d\\] &gt; 45\n</code></pre> <p>Pandas has various other features among these for creating new series of data to accessing components making it the ultimate hack for aspiring data scientists.</p> <p>Library link: https://pypi.org/project/pandas/</p> <p>GitHublink: https://github.com/pandas-dev/pandas</p> <p>NumPy</p> <p>NumPy (Numerical Python) is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with an extensive collection of high-level mathematical functions to operate on these arrays. It has the benefits of smaller memory consumption and faster runtime behavior. It has uses in various other developing fields like machine learning and data science. We can also combine it with other libraries to further enhance its applications.</p> <p>Features of NumPy:</p> <ul> <li>High-performance N-dimensional array object.</li> <li>It contains tools for integrating code from C/C++ and Fortran.</li> <li>It contains a multidimensional container for generic data.</li> <li>Additional linear algebra, Fourier transform, and random number capabilities.</li> <li>It consists of broadcasting functions. It broadcasts the shape of smaller arrays according to the larger ones.</li> <li>It had data type definition capability to work with various databases.</li> </ul> <p>Applications of NumPy:</p> <ul> <li>Numpy with Pandas is used for faster computations. When we use both the libraries together it is a very helpful resource for scientific computations.</li> <li>NumPy with Pandas is used to generate the graphs of the results. We enhance it further with the use of graphic toolkits like PyQt and wxPython.</li> <li>NumPy with SciPy is used to generate the graphs of the results. We enhance it further with the use of graphic toolkits like PyQt and wxPython.</li> <li>The use of Tkinter along with NumPy is user friendly. We can easily convert the array objects into image objects.</li> </ul> <p>Understanding NumPy:</p> <ul> <li>Shape Manipulations  \u2014 Users can change array dimensions at runtime if the output produces the same number of elements. We apply np.reshape(\u2026)  function on the array. The reshape function is useful for performing various operations. For example, we use it to broadcast two dissimilar arrays.</li> <li>Array Generation \u2014 We can generate array data set for implementing various functions. We can also generate a predefined set of numbers for the array elements using the np.arrange(\u2026)  function. Reshape function is useful to generate a different set of dimensions.</li> <li>Array Dimensions \u2014 Numpy consists of both one and multidimensional arrays. Some functions have restrictions on multidimensional arrays. It is then necessary to transform those arrays into one-dimensional arrays. We can transform multi-dimensional to single dimension using np.ravel(..)</li> </ul> <p>Code- Single Dimensional NumPy Array</p> <pre><code>import numpy as npa=np.array(\\[1,2,3\\])print(a) \u2014 \\[1 2 3\\]\n</code></pre> <p>Ouput -</p> <pre><code>\\[1 2 3\\]\n</code></pre> <p>Code- NumPy array occupies less memory as compared to list</p> <pre><code>import numpy as npimport timeimport sysS= range(1000)print(sys.getsizeof(5)\\*len(S))D= np.arange(1000)print(D.size\\*D.itemsize)\n</code></pre> <p>Output -</p> <pre><code>140004000\n</code></pre> <p>The above output shows that the memory allocated by list (denoted by S) is 14000 whereas the memory allocated by the NumPy array is just 4000. From this, you can conclude that there is a major difference between the two and this makes Python NumPy array as the preferred choice over list.</p> <p>Library Link: https://numpy.org/install/</p> <p>GitHub Link:https://github.com/numpy/numpy</p> <p>TensorFlow</p> <p>TensorFlow is a free and open-source software library for machine learning and artificial intelligence. It can be used across a range of tasks but has a particular focus on the training and inference of deep neural networks. TensorFlow can be used in a wide variety of programming languages, most notably Python, as well as Javascript, C++, and Java. This flexibility lends itself to a range of applications in many different sectors.</p> <p>Features of TensorFlow:</p> <ul> <li>AutoDifferentiation: It is the process of automatically calculating the gradient vector of a model with respect to each of its parameters</li> <li>TensorFlow includes an \u201ceager execution\u201d mode, which means that operations are evaluated immediately as opposed to being added to a computational graph which is executed later.</li> <li>TensorFlow provides an API for distributing computation across multiple devices with various distribution strategies.</li> <li>To train and assess models, TensorFlow provides a set of loss functions. These loss functions compute the \u201cerror\u201d or \u201cdifference\u201d between a model\u2019s output and the expected output.</li> <li>In order to assess the performance of machine learning models, TensorFlow gives API access to commonly used metrics.</li> <li>TensorFlow offers a set of optimizers for training neural networks, including ADAM, ADAGRAD, and Stochastic Gradient Descent (SGD).</li> </ul> <p>Applications of TensorFlow:</p> <ul> <li>Image recognition: It is used by Mobile companies, social media, and other telecom houses. Image recognition consists of pixel and pattern matching to identify the image and its parts.</li> <li>Voice Recognition: It is done using Automatic speech recognition which is trained using TensorFlow. These systems convert the human voice into text or computer understandable code by digitizing it.</li> <li>Video Detection: Here uses of TensorFlow include self-driving car systems, automation, and many automotive machines.</li> <li>Text-based applications: The text messages, reactions, comments, tweets, stock results etc are a means of data. This processing of data is done using TensorFlow for the analysis purpose and reaching the expected sales.</li> </ul> <p>Understanding TensorFlow:</p> <p>The first argument should be tensors, followed by basic Python parameters. The last argument is name with a default value of None. Operations should contain an extensive Python comment with Args and Returns declarations that explain both the type and meaning of each value. Possible shapes, dtypes, or ranks should be specified in the description.</p> <p>Code -</p> <pre><code>\\# Import \\`tensorflow\\`import tensorflow as tf# Initialize two constantsx1 = tf.constant(\\[1,2,3,4\\])x2 = tf.constant(\\[5,6,7,8\\])  \n\\# Multiplyresult = tf.multiply(x1, x2)# Print the resultprint(result)\n</code></pre> <p>Output -</p> <pre><code>Tensor(\u201cMul:0\u201d, shape=(4,), dtype=int32)\n</code></pre> <p>Library Link: https://www.tensorflow.org/install</p> <p>GitHub Link: https://github.com/tensorflow/</p> <p>MatPlotLib</p> <p>Matplotlib is a plotting library for the Python programming language and its numerical mathematics extension NumPy. It provides an object-oriented API for embedding plots into applications using general-purpose GUI toolkits. Matplotlib is designed to be as usable as MATLAB, with the ability to use Python, and the advantage of being free and open-source.</p> <p>Features of MatPlotLib :</p> <ul> <li>Semantic way to generate complex, subplot grids.</li> <li>Setting the aspect ratio of the axes box.</li> <li>Colored labels in legends.</li> <li>Ticks and labels.</li> <li>rcParams can be passed as Decorators.</li> <li>3D plots now support minor ticks</li> </ul> <p>Applications of MatPlotLib :</p> <ul> <li>Create publication quality plots.</li> <li>Make interactive figures that can zoom, pan, update.</li> <li>Customize visual style and layout.</li> <li>Export to many file formats .</li> <li>Embed in JupyterLab and Graphical User Interfaces.</li> <li>Use a rich array of third-party packages built on Matplotlib.</li> </ul> <p>Understanding MatPlotLib :</p> <ul> <li>matplotlib.pyplot.figure: Figure is the top-level container. It includes everything visualized in a plot including one or more  Axes.</li> <li>matplotlib.pyplot.axes: Axes contain most of the elements in a plot: Axis, Tick, Line2D, Text,  etc., and sets the coordinates. It is the area in which data is plotted. Axes include the X-Axis, Y-Axis, and possibly a Z-Axis, as well.</li> </ul> <p>Code -</p> <p>Creating your first plot \u2014 The Figure is the first step and the key to unlocking the power of this package. Next, you see that you initialize the axes of the Figure in the code chunk above with fig.add_axes():</p> <pre><code>\\# Import \\`pyplot\\`  \nimport matplotlib.pyplot as plt  \n\\# Initialize a Figure   \nfig = plt.figure()  \n\\# Add Axes to the Figure  \nfig.add\\_axes(\\[0,0,1,1\\])\n</code></pre> <p>Output -</p> <pre><code>&lt;matplotlib.axes.\\_axes.Axes at 0x7f98466de4a8&gt;\n</code></pre> <p>Library Link: https://matplotlib.org/stable/users/installing/index.html</p> <p>GitHub Link:https://github.com/matplotlib/matplotlib</p> <p>Conclusion</p> <p>In this blog, you learned about the best Python libraries for machine learning. Python libraries and packages are a set of useful modules and functions that minimize the use of code in our daily lives. There are over 137,000 libraries and 198,826 packages for Python, ready to make developer programming easier. These libraries and packages are intended for a variety of modern solutions.</p> <p>Every library has its own positives and negatives. These aspects should be taken into account before selecting a library for the purpose of machine learning and the model\u2019s accuracy should also be checked after training and testing the models so as to select the best model in the best library to do your task. And may this help you in keeping up with the growing popularity and development of the Python programming language.</p> <p>Authors</p> <p>Kashin Mittal &amp; Prerna Mittal</p>"},{"location":"blogs/MathematicsML/","title":"Mathematics in Machine Learning","text":""},{"location":"blogs/MathematicsML/#introduction","title":"Introduction","text":"<p>Machine Learning is a division of AI that focuses on building applications by processing available data accurately. The primary aim of machine learning is to help computers process calculations without human intervention.</p> <p>The question that arises here is, so how do we feed the data to the machine? How would the machine now perform operations on this dataset and provide precise results? This is where mathematics comes into play.</p> <p>To all those who are thinking, \u201cWhat\u2019s the use of learning the mathematics behind machine learning algorithms? We can easily use the widely available libraries in Python and R to build models!\u201d While that is true, it is vital to note that these libraries and functions themselves work on the basis of mathematical concepts. Without understanding the \u2018why\u2019s\u2019 and \u2018how\u2019s\u2019 behind the code, one can never truly appreciate the beautiful field of Artificial Intelligence or any computer science domain for that matter.</p> <p>There are four pillars of mathematical support to ML. Let us now tackle each of these, one by one.</p> <p></p>"},{"location":"blogs/MathematicsML/#linear-algebra","title":"Linear Algebra","text":"<p>Linear algebra can transform datasets into matrices on which several operations can be performed.  NumPy  is such a library used in Machine Learning which performs several operations on N-dimensional array.</p> <p>In machine learning, you fit a model on a dataset. This is the table-like set of numbers where each row represents an observation and each column represents a feature of the observation. For example, below is a snippet of the  Iris flowers dataset:</p> <p></p> <p>Iris flower dataset</p> <p>This data is in fact a matrix: a key data structure in linear algebra.</p> <p>Further, when you split the data into inputs and outputs to fit a supervised machine learning model, such as the measurements and the flower species, you have a matrix (X) and a vector (y). The vector is another key data structure in linear algebra.</p> <p>While working with images or photographs in computer vision applications, each image that you work with is itself a table structure with a width and height and one pixel value in each cell whose value ranges from 0 to 255. In case of black and white images there is one channel and in case of RBG there are three channels. A photo is yet another example of a matrix from linear algebra. Operations on the image, such as cropping, scaling, shearing, and so on are all described using the notation and operations of linear algebra which takes us to the next section of datasets \u2014 performing operations on them.</p> <p>Linear regression is a method from statistics for describing the relationships between variables. It uses a linear algebra notation \u2014 y=Ab. Where y is the output variable, A is the dataset and b are the model coefficients. There are many ways to describe and solve the linear regression problem, i.e. finding a set of coefficients that when multiplied by each of the input variables and added together results in the best prediction of the output variable. One such method is SVD (Singular value decomposition)</p> <p>SVD deals with decomposing a matrix into a product of 3 matrices as shown:</p> <p></p> <p>If the dimensions of A are m x n:</p> <ul> <li>U is an m x m matrix of Left Singular Vectors</li> <li>S is an m x n rectangular diagonal matrix of Singular Values arranged in decreasing order</li> <li>V is an n x n matrix of Right Singular Vector</li> </ul> <p>This decomposition allows us to express our  original matrix as a linear combination of low-rank matrices.</p> <p></p> <p>Note:  The rank of a matrix is the maximum number of linearly independent row (or column) vectors in the matrix. A vector  r  is said to be linearly independent of vectors  r1  and r2  if it cannot be expressed as a linear combination of  r1  and  r2. (i.e. r \u2260 ar1 + br2)</p> <p>Thus, the rank of a matrix can be thought of as a representative of the amount of unique information represented by the matrix. Higher the rank, higher the information.</p> <p>In a practical application, you will observe that only the first few, say k, singular values are large. The rest of the singular values approach zero. As a result, terms except the first few can be ignored without losing much of the information. See how the matrices are truncated in the figure below:</p> <p></p> <p>Once we have established the required SVD jargon, we can use it to find approximate solutions for real-world problems. In this example, I am going to use the  Boston house-prices dataset. The house-prices data matrix A contains 506 rows (representing individual houses), and 13 columns (each describing a different characteristic of the houses). Some of these 13 features include:</p> <p>\u00b7 Per capita crime rate by town</p> <p>\u00b7 The average number of rooms per dwelling</p> <p>\u00b7 Weighted distances to five Boston employment centers</p> <p>We want to predict the median value home price in $1000\u2019s. These measurements are real values ranging from 5 to 50, and they represent the b vector in our system of equations Ax=b.</p> <p>As usual, the matrix has many more rows than columns. This means that we cannot invert A to find the solution to Ax= b. Also, it drastically reduces the possibilities of finding a solution. Indeed, such a solution would only be possible if b is a linear combination of the columns of A. However, using the SVD, we will be able to derive the pseudo-inverse A+, to find the best approximate solution in terms of least squares \u2014 which is the projection of the vector b onto the subspace spanned by the columns of A.</p> <p>Applications of SVD in Image Processing</p> <p>Face Recognition:</p> <ol> <li> <p>Collect a training set of faces as the training set</p> </li> <li> <p>Find the most important features by finding the directions of maximum variance \u2014 the eigenvectors or the eigenfaces.</p> </li> </ol> <p>(Note: If non-zero e is an eigenvector of the 3 by 3 matrix A, then (Ae=\u03bbe) for some scalar. This scalar is called an eigenvalue of A. This may be rewritten as Ae=\u03bbIe and in turn as (A\u2212\u03bbI)e=0 . The value of lambda which satisfies this equation is eigenvalue and the corresponding vector values after substituting it back into the matrix equation are the eigenvectors)</p> <ol> <li> <p>Choose top M eigenfaces corresponding to the highest eigenvalues. These eigenfaces now define a new face space</p> </li> <li> <p>Project all the data in this face space</p> </li> <li> <p>For a new face, project it into the new face space, find the closest face(s) in the space, and classify the face as a known or an unknown face</p> </li> </ol> <p></p> <p>Results after using above algorithm for face detection</p> <p>Special Clustering:</p> <p>Clustering  is the task of grouping similar objects together. It is an unsupervised machine learning technique. Consider the below case:</p> <p></p> <p>Using SVD, we can obtain the following result.</p> <p></p> <p>These are the basic steps to obtain the above result:</p> <ul> <li>Start with the  Affinity matrix (A)  or the  Adjacency matrix  of the data. This represents how similar one object is to another. In a graph, this would represent if an edge existed between the points or not</li> <li>Find the  Degree matrix (D)  of each object. This is a diagonal matrix with entry  (i,i) equal to the number of objects object  i  is similar to</li> <li>Find the  Laplacian (L)  of the Affinity Matrix:  L = A \u2014 D</li> <li>Find the highest  k  eigenvectors of the Laplacian Matrix depending on their eigenvalues</li> <li>Run k-means  on these eigenvectors to cluster the objects into k classes</li> </ul>"},{"location":"blogs/MathematicsML/#calculus","title":"Calculus","text":"<p>In Machine Learning, we try to find the inputs which enable a function to best match the data. The slope or descent describes the rate of change off the output with respect to an input. Determining the influence of each input on the output is also one of the critical tasks. All this requires a solid understanding of Multivariate Calculus.</p> <p>Gradient descent algorithm:</p> <p>Let\u2019s say you are playing a game where the players are at the top of a mountain, and they are asked to reach the lowest point of the mountain. Additionally, they are blindfolded. So, what approach do you think would make you reach the lake?</p> <p>The best way is to observe the ground and find where the land descends. From that position, take a step in the descending direction and iterate this process until we reach the lowest point.</p> <p>Similarly, given a cost function, the goal of the gradient descent algorithm is to minimize the given function (say cost function). To achieve this goal, it performs two steps iteratively:</p> <ol> <li>Compute the gradient  (slope), the first order derivative of the function at that point</li> <li>Make a step (move) in the direction opposite to the gradient, opposite direction of slope increases from the current point by alpha times the gradient at that point</li> </ol> <p></p> <p>Alpha is called Learning rate \u2014 a tuning parameter in the optimization process. It decides the length of the steps.</p> <p>Back-propagation algorithm :</p> <p>The  Back propagation algorithm in neural network  computes the gradient of the loss function for a single weight by the chain rule. It efficiently computes one layer at a time, output for every  neuron  from the input layer, to the hidden layers, to the output layer.</p> <p>Let us have an artificial neural network module with n layers. Each layer \u2018i\u2019 has a weight of \u2018Wi\u2019 and outputs are calculated by matrix multiplications between inputs and weights. So, for instance, if we set up the input to the artificial neural network as \u2018X0,\u2019 then we have the output of the first layer as:</p> <p></p> <p>Where \u2018X0\u2019 is the input to the module, \u2018W1\u2019 is the weight for the first layer and \u2018F1\u2019 is the activation function for the first layer. So, the output of the nth and last layer of a network can be defined as:</p> <p></p> <p>Where \u2018X(n-1)\u2019 is the input to the layer \u2018n,\u2019 \u2018Wn\u2019 is the weight for the layer \u2019n\u2019 and \u2018Fn\u2019 is the activation function for the same layer. Now, let us define a loss function \u2018L\u2019 that compares the outputs \u2018Xn\u2019 with the ground truth \u2018G.\u2019 So, the error \u2018E\u2019 can be expressed as E = L(G,Xn). Differentiating with respect to weight \u2018Wn,\u2019 we get:</p> <p></p> <p>Using the same logic, we can get the generalized series for the (n-1)th layer as well. It is important to note here that \u2018Wn\u2019 does not update as soon as the gradient is calculated, it waits for the gradients of all of the weights to be calculated and then all the weights are updated together. As a result of this, the \u2018Wn\u2019 term in the in the (n-1) differential still points to the weights before the update.</p>"},{"location":"blogs/MathematicsML/#statistics-probability","title":"Statistics &amp; Probability","text":"<p>After working on dataset and optimization next step is to analyze the result. This is where statistics \u2014 specifically, graphical representations are helpful. It gives an insight into the accuracy of the trained model. While probability in general helps us understand whether the points in our dataset are perfectly fitting, overfitting or underfitting in the model, we will discuss one algorithm in particular.</p> <p>Naive Bayes Algorithm:</p> <p>The fundamental Naive Bayes assumption is that each feature makes an:</p> <p>\u00b7 independent</p> <p>\u00b7 equal</p> <p>Now, before moving to the formula for Naive Bayes, it is important to know about Bayes\u2019 theorem. Bayes\u2019 Theorem finds the probability of an event occurring given the probability of another event that has already occurred. Bayes\u2019 theorem is stated mathematically as the following equation:</p> <p></p> <p>This can be rewritten mathematically for the purpose of calculating desirable classes from a large number of datasets. For instance, if we have a dataset on the predictability of a match happening with a few parameters, it is basically bayes theorem.</p> <p></p> <p>Here x1,x2\u2026.xn represent the dependent features and y is class variable. By substituting for  X , expanding using the chain rule and inserting proportionality since denominator is constant, we can obtain a function to predict results.</p>"},{"location":"blogs/MathematicsML/#summary","title":"Summary","text":"<p>Math and machine learning are inseparable. A true AI scientist always has his math right. Hope this blog gave all of you an insight on the vitality of understanding the nuances math can offer to machine learning and delve deeper into it.</p>"},{"location":"blogs/MathematicsML/#bibliography","title":"Bibliography","text":"<p>cs231n.stanford.edu/slides/2018/cs231n_2018_ds02.pdf</p> <p>LinearAlgebraSVD.pdf (upc.edu)</p> <p>10 Examples of Linear Algebra in Machine Learning (machinelearningmastery.com)</p> <p>How to Develop a Naive Bayes Classifier from Scratch in Python (machinelearningmastery.com)</p>"},{"location":"blogs/TLE/","title":"Make your I/O fast(est)","text":"<p>C++ developers usually get accustomed to using  std::cin  and  std::cout  for standard I/O operations, but they aren\u2019t the fastest ones out there. If you are feeling lazy to change your code, you can just add the statements given below and enjoy the speed boost.</p> <p>The first statement disables the sync between C and C++ style I/O, so this may cause unknown errors if you combine them. For competitive coding, it\u2019s usually not required to use both so you can use it without any worries.</p> <p>The second statement unties  std::cin  with  std::cout. Whenever one of the streams is used, the other is flushed, but when you untie them, they no longer flush each other, which results in better performance. Of course, you can always use your old C friends,  scanf, and  printf. They are faster than  std::cin  and  std::cout  by about three times, but when compared to unsynchronized  std::cin  and  std::cout  they don\u2019t give much of a performance boost.</p> <p>Want it to be even more fast? Are you taking integer input? Oh, then you are in luck! Just copy this function, and you can take integer inputs in the fastest, thread-safe way.</p> <p>The function given above reads each character and converts them into an integer. This method is free from a lot of system calls that  scanf  has to make, like deducing the type of input.</p> <p>You must be wondering why I wrote \u201cthe fastest, thread-safe way.\u201d Well, because there is a faster way, but that makes it thread-unsafe. Want to use it? Replace  getchar()  with  getchar_unlocked()  and experience the beast. In competitive programming environments, you don\u2019t need to worry about being thread-safe unless you are doing concurrency related tasks, so go ahead with it!</p> <p>How do you believe what I say without any proof? Well, here it is. The different methods were benchmarked, and the results are presented below. If you want to look at the code used in the benchmark, I have uploaded it to a GitHub repository, which you can find  here.</p> <p></p> <p>Comparison of std::cin vs. other input methods</p>"},{"location":"blogs/TLE/#faster-vectors","title":"Faster Vectors","text":"<p>While vectors are fantastic because of their expandability, but the same attribute makes them slow too.  std::vector  is implemented as a dynamic array, which means that each time it needs to increase the size of the array, it creates another array double the size and then copy the elements from the previous array. If you know the size of the vector before you add items, reserving the space eliminates the overhead required to copy the elements because it creates an array at least as big as the reserved size.</p> <p>Where max is the number of elements you are going to store in the vector.</p> <p>Adding a reserve makes your code about 1.2x faster.</p> <p></p> <p>Comparison between  the time taken with and without reserve</p> <p>Again C style arrays or  std::array  is faster than using a vector any day, but its size has to be known at compile-time and thus isn\u2019t always feasible to use. So vectors are your best bet, and it\u2019s better to reserve the space beforehand.</p> <p>Another surprising thing about  std::vector  is the  at()  function. It seems to do the same thing as subscript operator  []  but when the performance is measured it is actually 3.1 times slower.</p> <p></p> <p>Comparison between  using at() function and subscript operator []</p> <p>That can do a lot of damage to the time taken by your program. The reason being is that the at operator has builtin checks for out of range values that the subscript operator doesn\u2019t, so if you give a value that is out of range it might give you a segmentation fault or cause unknown errors without telling you what has gone wrong while at will throw an exception.</p> <p>One final thing that you should know about  std::vector  is that you should never copy an  std::vector  to another manually using a loop and  push_back(), rather you should use assignment operator  =. The difference in speed is huge as apparent by the chart below.</p> <p></p> <p>Comparison between  using a loop and push_back() vs. assignment operator =</p> <p>This difference in performance is caused because when you are doing assignment it knows the size of the vector it is copying, and needs to call the memory manager only once to create the assigned vector\u2019s space and copy all the elements unlike the  push_back()  operation which makes a call to the manager for every element.</p>"},{"location":"blogs/TLE/#dont-just-add-append","title":"Don\u2019t just add, append","text":"<p>The fastest way to work with strings in C++ would be to use C style strings, i.e. character arrays, equivalent performance to character arrays, but one mistake programmers frequently make is to use the  +  operator to append to a string. The reason it is not suitable to use is that it creates another character array of the total size of both the operand strings and copies the first one to the array while concatenating the other to the newly created array. What you should do instead is use the  append()  function, or it\u2019s equivalent  +=  operator:</p> <p>OR</p> <p>Using the  +=  operator instead of + operator is better for any class that supports it. This helps in reducing the time taken and memory to create a new object and copy the first and then add the second object to it.</p> <p></p> <p>Comparison between  using + operator and += operator</p> <p>Also, when using  std::string  or any other class, it\u2019s best to initialize it using the constructor than using the assignment operator.</p>"},{"location":"blogs/TLE/#you-dont-need-stdlist","title":"You don\u2019t need std::list","text":"<p>If you don\u2019t know about  std::list, we are done here, but if you do and you are thinking about using it, then think again.  std::list  is a doubly-linked list, so the advantage it gives over  std::vector  is that it can remove and insert at any position in constant time. That can seem great when you need it, but vectors can be cached by the processor so sequential access is faster than when using  std::list.</p> <p>If you have to remove several elements from the middle of a vector, you can use  erase_if().  erase_if()  was introduced in C++ 20, but you can combine  remove_if()  and  erase()  together to create your custom  erase_if()  for previous versions of C++.</p> <p>You might see there is a variable called predicate. The predicate is a function that takes in an element from the vector and returns a bool. Typically, each time you erase an item from a vector, the ones after it are shifted forward, but if you use an  erase_if()  construct, the shifting is done after all the elements have been deleted, so it is great for removing multiple elements. An example predicate is given below.</p> <p>If you use the above function in the  erase_if()  expression:</p> <p>It will remove all the zeros from the vector v.</p> <p>If you want to see a comprehensive benchmark between  std::vector  and  std::list  you can take a look at this beautiful post by Baptiste Wicht  here. After reading the post, you might have a question in mind, \u201cIf  std::list  is worse than using  std::vector, then why is it even there in the standard library?\u201d It\u2019s because there are a few places where lists are better, i.e., when the elements being stored in the list are huge and not a lot of them can be fit in the cache, lists can dominate over vectors.</p>"},{"location":"blogs/TLE/#befriend-unordered_map","title":"Befriend unordered_map","text":"<p>std::map  is maintained as a binary search tree, and the main advantage of using map over unordered_map is that it sorts the elements according to the key. One other benefit of using  std::map  over  std::unordered_map  is that it supports pairs out of the box. However, the difference between O(log n) and O(1) can be the difference between a TLE and an AC solution. So let\u2019s look at how you can create your hash function for a pair of integers.</p> <p>This structure tries to return a unique integer for every pair it gets. You just need to plug this struct into your unordered_map and voila! Your hash table now supports  std::pair. <p>You can Google many more hash functions suited for different needs and choose your flavor.</p> <p>std::map  should be only used when sorting of elements is required other than that  std::unordered_map  is your friend. The same goes for  std::set  and  std::unordered_set.</p> <p>Also, you can use reserve with  std::unordered_map  too. In my benchmarks, it sped up the process of adding elements to the hash table 1.3x times.</p> <p></p> <p>Comparison between  creating a hash table with and without reserve</p> <p>If you want a faster hash table than unordered_map and you or your CP platform uses g++, there is excellent news. You can use  ___gnu_pbds::gp_hash_table_! It isn\u2019t part of the standard library but has almost the same interface as std::unordered_map but is much faster.</p> <p></p> <p>Comparison between  unordered_map and gp_hash_table</p> <p>___gnu_pbds::gp_hash_table_  is faster than  std::unordered_map  because it drops a lot of many unnecessary features that STL has to retain. If you want a better explanation, you can look at the comment  here, and if you want more insight, you can see this post  here.</p> <p>There is one more optimization that you can do for  std::unordered_map  that is setting its  max_load_factor  to 0.25. The load factor is defined as the ratio of the number of elements in the hash table to the number of buckets. Keeping  max_load_factor  at 0.25 means at least \u00be of the buckets will be empty. This reduces collisions in the hash table; therefore, the lookup time but also increases the space taken by your hash table. I couldn\u2019t find much of a performance gain when using it, but you can try it if  std::unordered_map  seems to perform worse than you expected, and you can\u2019t switch to  gp_hash_table.</p>"},{"location":"blogs/TLE/#conclusion","title":"Conclusion","text":"<p>To summarize:</p> <ol> <li>Use  fastscan()  for the fastest integer input and  std::cin  without sync for the rest.</li> <li>Use reserve with  std::vector  and  std::unordered_map  as much as possible.</li> <li>Use assignment operator to copy vectors and operator  []  instead of  at()  function</li> <li>Use addition assignment operator instead of addition and then assignment for strings as well as other classes that support it.</li> <li>Don\u2019t use  std::list  use  std::vector  instead.</li> <li>Use  std::map  and  std::set  when the keys need to be sorted otherwise use  std::unordered_map  or  _std::unordered_se_t, respectively.</li> </ol> <p>There are a lot more optimizations that you can achieve in C++. An example of a small one would be to use bit shift operators instead of multiplying or dividing by powers of 2, as shown  here.</p> <p>I would encourage you to explore more on your own, benchmark any such tips you may find, and maybe comment them down below. I had fun making this post and hope you had fun reading it too and learned something new.</p> <p>P.S.:  I have assumed that the code is compiled without any compiler optimization because the primary target audience of this article is competitive coders.</p>"},{"location":"blogs/TLE/#references","title":"References","text":"<p>Apart from the ones linked in the article here are some sites and books that I referred from:</p> <ul> <li>Fast IO Optimization in C++ by Arun Prasad</li> <li>6 Tips to supercharge C++11 vector performance  by  Deb Haldar</li> <li>CPP Optimizations Diary by Davide Faconti</li> <li>Optimized C++: Proven Techniques for Heightened Performance  by Kurt Guntheroth</li> <li>C++ Reference</li> <li>And of course loads and loads of Stack Overflow searches</li> </ul>"},{"location":"blogs/breaking_the%20_ice_with_graphs/","title":"Breaking the Ice with Graphs","text":""},{"location":"blogs/breaking_the%20_ice_with_graphs/#an-introduction-to-graph-theory-in-programming-part-1","title":"An Introduction to Graph Theory in Programming Part-1","text":"<p>Photo by  Chris Ried  on  Unsplash</p> <p>Algorithms and Data Structures can be a scary place for anyone new to Computer Science and Competitive Coding. Graphs are often considered to be one of the scarier data structures out there.</p> <p>But graphs are super fun once you get a hang of them.\ud83d\ude03</p> <p>Let\u2019s get started.</p>"},{"location":"blogs/breaking_the%20_ice_with_graphs/#what-is-a-graph-data-structure","title":"What is a Graph Data Structure?","text":"<p>A graph is a tool in mathematics that is used to depict the relationship between entities.</p> <p></p> <p>A simple directed graph</p> <p>The circles are called vertices and represent some entities. These could be anything ranging from stations in a rail network to members of a family.</p> <p>The lines are called edges and represent some relation.</p> <p>There are 2 types of graphs \u2014 directed graphs and undirected graphs. The one shown above is directed, which means that the edges go in 1 direction. So I can go from 1 to 2 but not 2 to 1. Getting rid of the arrows would make it an undirected graph which would mean all edges are 2-way.</p> <p>Graphs are extremely useful wherever we have to solve problems involving objects related to each other. In the real world computer networks, social networks, cities connected by highways can all be analyzed as graph problems. The applications are endless \u2014 from calculating the similarity between 2 twitter users or calculating the optimal path a delivery truck must take to city planning and water supply management.</p> <p>Basic Terms:</p> <ul> <li>Walk: Any sequence of edges joining a sequence of vertices. Suppose you go from node 1 to 2 to 4 \u2014 it would constitute a walk 1-&gt;2,2-&gt;4.</li> <li>Trail: A walk in which all edges are distinct. So, you do not travel a given edge more than once.</li> <li>Cycle: A non-empty trail starting and ending at the same vertex.</li> </ul>"},{"location":"blogs/breaking_the%20_ice_with_graphs/#representing-a-graph-in-a-computer","title":"Representing a Graph in a Computer","text":"<p>There are 2 popular ways to represent a graph in code:</p> <ol> <li> <p>Adjacency matrix</p> </li> <li> <p>Adjacency List</p> </li> </ol>"},{"location":"blogs/breaking_the%20_ice_with_graphs/#adjacency-matrix","title":"Adjacency Matrix","text":"<p>Suppose a graph has n vertices. We can represent the connections between them by using an n x n matrix.</p> <p>Follow these steps:</p> <ol> <li>Initialize an n x n matrix with 0s( if the vertices are numbered from 1 it would be convenient to use a (n+1)x(n+1) matrix ignoring the 0th row and column).</li> <li>If there is an edge from vertex u to v set matrix[u][v]=1. Do this for each edge.</li> </ol> <p>Your adjacency matrix is ready\u2728.</p> <p>Thus every connection is represented by a 1 at the appropriate position.</p> <p></p> <p>Adjacency Matrix for the Graph shown above.</p>"},{"location":"blogs/breaking_the%20_ice_with_graphs/#adjacency-list","title":"Adjacency List","text":"<p>An Adjacency list is a list of lists.</p> <p>You have a main list with n sub-lists corresponding to the n vertices.</p> <p>The \u2018ith\u2019 sub-list contains vertices that vertex \u2018i\u2019 is connected to.</p> <p>For Example, if there edges from vertex 1 to 2,3 and 4, then the first sub-list will contain 2,3 and 4.</p> <p></p> <p>Adjacency List for the Graph shown above.</p> <p>In C++ this structure can easily be implemented by using 2-d vectors.</p>"},{"location":"blogs/breaking_the%20_ice_with_graphs/#matrix-vs-list","title":"Matrix Vs List:","text":"<p>(|V| stands for number of vertices and |E| stands for number of edges.)</p> <p>A matrix has certain advantages:</p> <ul> <li>We can check if an edge exists between 2 vertices u and v by checking mat[u][v] ie. in O(1) time. But in an adjacency list, you would have to traverse the whole sub-list of u and hence the worst case could take O(|V|) time if u is connected to every other vertex(Adjacency lists can be implemented in other ways to eliminate this problem).</li> <li>Removing or inserting an edge can be done in constant time by changing one value again O(1) while an adjacency list could take O(|V|).</li> </ul> <p>A List has the following advantage:</p> <ul> <li>It takes much less space as compared to a matrix as long as every vertex is not connected to every other vertex O(|V|+|E|). But a matrix always takes O(|V|\u00b2) space, which is often not suitable for competitive coding problems.</li> </ul> <p>Now let's get to the good stuff!</p>"},{"location":"blogs/breaking_the%20_ice_with_graphs/#graph-traversals","title":"Graph Traversals","text":"<p>There are 2 classic approaches to traversing a graph both of which take time complexity of O(|V|+|E|).</p> <ol> <li>Depth First Search</li> <li>Breadth First Search</li> </ol>"},{"location":"blogs/breaking_the%20_ice_with_graphs/#depth-first-search","title":"Depth First Search","text":"<p>Depth First Search popularly known as DFS, in essence, means you follow a path till the very end before trying out another, hence depth-first. It is generally done recursively or using a stack.</p> <p>The pseudo-code:</p> <p>//n is number of vertices visited[n]={0}; dfs(source){     dfs[source]=1;     for(vertex u adjacent to source){         if(!visited[v]){            dfs(u);          }      } }</p> <p>In simple words, you maintain an array to remember the vertices visited so far. Initially, it would be filled with 0 or false. On visiting a vertex u you would make arr[ u]=1 or true. Then you visit an unvisited vertex adjacent to your current vertex and set that vertex as visited and then visit its neighbour and so on \u2018recursively\u2019 until the vertex you are in has no unvisited neighbours.</p> <p>Once this stage is reached you return to the previous recursive call, and visit the next unvisited neighbour and so on.</p> <p>In the above graph, you would visit vertices in the following order: 1 2 4 3</p>"},{"location":"blogs/breaking_the%20_ice_with_graphs/#breadth-first-search","title":"Breadth First Search","text":"<p>Breadth First Search popularly known as BFS, in essence, means you visit all unvisited neighbours of the current vertex first and then do the same for the next vertex. It is generally done using a queue.</p> <p>The pseudo-code:</p> <p>//n is number of vertices visited[n]={0}; bfs(source){     visited[source]=1;     Queue q;     q.push(source);     while(!q.empty()){         cur=q.pop();         for(vertex u adjacent to source){            if(!visited[u]){               visited[u]=1;               q.push(u);            }          }      } }</p> <p>In the above graph, you would visit vertices in the following order: 1 2 3 4</p>"},{"location":"blogs/breaking_the%20_ice_with_graphs/#some-basic-applications","title":"Some Basic Applications:","text":"<ol> <li>In an unweighted graph, BFS would give the shortest path from source to any given node.</li> <li>DFS can be used to easily detect cycles.</li> </ol> <p>Whether you\u2019re a competitive programmer, a CS student, a network administrator or planner, graphs are an indispensable tool worth using.</p> <p>You\u2019ve now got a taste of graphs and understand the concepts that will enable you to dive deeper into the world of graphs.</p> <p>To get to the next stage of your exploration of graphs follow this link  https://medium.com/the-acm-manipal-blog/navigating-through-graphs-5105964aced7</p>"},{"location":"blogs/navigation_through_graphs/","title":"Navigating Through Graphs","text":""},{"location":"blogs/navigation_through_graphs/#an-introduction-to-graph-theory-in-programming-part-2","title":"An Introduction to Graph Theory in Programming Part-2","text":"<p>Photo by  Markus Spiske  on  Unsplash</p> <p>Now that we know graph representation and traversals, let\u2019s start exploring graphs.</p> <p>Since graphs can be used to represent connections between cities or supply units and consumers, one major application of graphs is to analyze the best possible routes to go from one point to the other.</p>"},{"location":"blogs/navigation_through_graphs/#shortest-path-algorithms","title":"Shortest Path Algorithms","text":"<p>The graphs we have seen so far did not have weights on edges. In other words, we considered each edge to have the same length or cost of traversal.</p> <p>However, most applications edges have weights or costs associated with them which could represent the length of a highway in a system of cities, the delay of a route in a computer network etc.</p> <p>Cost can be represented in several ways. We could modify our adjacency list or matrix to store cost.</p> <p>When we modify the adjacency matrix to store cost, it\u2019s called the cost matrix. In the cost matrix, cost[u][v] would denote the cost to go from u to v.Instead of storing 0 for non-adjacent vertices, we could store a cost of INFINITY and instead of storing a 1 for adjacent vertices, we could store the cost of the edge connecting them. The cost[i][i] would be 0 as there would be no cost to go from vertex i to the same vertex.</p> <p>Adjacency List could be modified to store pairs of (adjacent vertex, cost) in the sub-lists.</p> <p>|V| denotes number of vertices and |E| denotes number of edges.</p>"},{"location":"blogs/navigation_through_graphs/#floyd-warshall-algorithm","title":"Floyd Warshall Algorithm","text":"<p>The Floyd Warshall algorithm is an application of dynamic programming in graph theory. It takes the cost matrix as input and gives us the shortest path from every node to every other node. (The graph must not contain negative cycles, because if negative cycles were present we could make the cost arbitrarily small.)</p> <p>The pseudocode:</p> <p>floyd_warshall(cost){//number of vertices is n   res=costfor k-&gt; 1 to n:for i-&gt;1 to n:for j-&gt;1 to n:res[i][j]=min(res[i][j],res[i][k]+res[k][j])   return res}</p> <p>We use dynamic programming here \u2014 we use a series of |V| matrices to get the final result (we don\u2019t actually store n different matrices but modify the same matrix). In the kth iteration of the outer loop, we compute the shortest path \u2014 where the intermediate node is numbered k or less \u2014 from every vertex to every other vertex.</p> <p>So in the 0th iteration, the res matrix has the shortest path between all vertices with intermediate vertices numbered 0 or less (so no intermediate vertices) which is the cost matrix itself.</p> <p>In the 1st iteration, we would have shortest paths, with intermediate vertices numbered 1 or less and so on. By the end of n iterations, we get the shortest path between all vertices with any set of intermediate vertices allowed and hence this is our result.</p> <p>Why does it work?</p> <p>Let us say we\u2019re at the kth iteration of the outer loop. We already have the shortest distances with intermediate vertices numbered k-1 or less from the previous iteration.</p> <p>Now suppose take the case of the shortest path from some vertex i to some vertex j. In the current iteration, we need to find the shortest path from i to j with intermediate vertices less than or equal to k.</p> <p>Now there are 2 possibilities- the shortest path could include k or not. If it does not include k then the intermediate vertices are numbered k-1 or less and we already computed cost for this in the previous iteration. If it does include k (k appears only once as there are no negative cycle and going through a cycle would not give minimum cost path), the path from i to k can only have intermediate vertices numbers k-1 or less and the path from k to j must have vertices numbered k-1 or less. We have already calculated these distances in the previous iteration and they are available in res[i][k] and res[k][j]. Now taking the best of the 2 cases \u2014 including k and not including k \u2014 we get our result for the kth iteration.</p> <p>When Should You Use the Floyd-Warshall Algorithm:</p> <p>Remember:- Floyd-Warshall applies to both directed and undirected graphs with both positive and negative edge weight. But there  shouldn\u2019t be negative length cycles!</p> <p>This algorithm has O(|V|\u00b3) time complexity.</p> <p>You can use this algorithm when you have a relatively small number of vertices and many queries.</p> <p>It is definitely not worth doing if you need to find the shortest path between just 2 vertices.</p> <p>You cannot use the algorithm in competitive coding questions with number of vertices of the order of 10\u2075.</p>"},{"location":"blogs/navigation_through_graphs/#dijkstras-algorithm","title":"Dijkstra\u2019s Algorithm:","text":"<p>This is a single-source shortest path algorithm \u2014 it gives you the shortest paths from one vertex to all the other vertices.  This algorithm doesn\u2019t work with negative edge weights.</p> <p>Dijkstra's algorithm follows a greedy approach and chooses the least cost path at each step. When you visit a node the current distance to the node from the source is the least and it cannot get smaller than that.</p> <p>The pseudocode:</p> <p>djikstra(){Initialize distances to be INF;Make distance[source]=0;set unvisited={all vertices};for i-&gt;1 to |V|:current=node with least distance;unvisited.remove(current);for edges from current to each unvisited vertex u:distance[u]=min(distance[u],distance[current]+cost[current][u]);}</p> <p>Why does it work?</p> <p>The array distances hold the distance or cost from source to all vertices. It is initialized to infinity and then the distance to the source is made 0.</p> <p>At a given iteration, we choose the vertex say \u2018u\u2019 with least distance and this is the final shortest distance for the given vertex. Remember, this distance is the shortest distance considering the previously visited vertices as potential penultimate vertices (the vertex that comes before the last vertex in the shortest path). Now, if there cannot be a shorter path having any other vertex as the penultimate vertex because then we would have to traverse a longer distance to that vertex + distance from that vertex to u (and there are no negative edges).</p> <p>There are 2 ways to implement Dijkstra\u2019s Algorithm:</p> <p>One of time complexity O(|V|\u00b2) and the other of O(|E|log(|V|)).</p> <p>We can implement it with order O(|V|\u00b2) by going through the distance array linearly to find maximum at each iteration.</p> <p>We can implement it with order O(|E|log(|V|)) by using a priority queue to get the minimum distance path.</p> <p>In C++ we can effectively use the set of STL to get the minimum and also for updating the distances easily.</p> <p>Which implementation should you use:</p> <p>If your graph is very dense( most of the vertices are connected to each other) and the edges are of the order of |V|\u00b2, then the O(|V|\u00b2) implementation is preferable as the other one would give O(|V|\u00b2log(|V|)).</p> <p>But if |E| is of the order of |V|, you should go with O(|E|log(|V|)).</p> <p>Bonus Tip:</p> <p>We\u2019ve talked about single source to all other vertices but finding shortest path from all vertices to a single destination can also be done similarly.</p> <p>Just invert all edges and do Dijkstra from the destination. The result would be shortest path from all vertices to the destination.\u2728</p> <p>In short, using Dijkstra is preferable to Floyd-Warshall when you need the distance from only one vertex. However, it cannot handle negative weights.</p>"},{"location":"blogs/navigation_through_graphs/#bellman-ford-algorithm","title":"Bellman-Ford Algorithm:","text":"<p>Bellman-ford algorithm is also a single source shortest path algorithm like Dijkstra but it can handle negative weights. However, negative length cycles are not allowed for the obvious reason of arbitrarily small distance.</p> <p>The pseudocode:</p> <p>bellman-ford(){Initialize distances to be INF;Make distance[source]=0;for i-&gt;1 to |V|-1:for each edge from u to v:distance[v]=min(distance[v],distance[u]+cost[u][v])}</p> <p>At iteration i, we get the smallest length from source to all vertices with maximum of i-1 intermediate vertices in between. So at the end of |V|-1 iterations, we have taken into account all possibilities.</p> <p>When should you use it:</p> <p>This algorithm has a complexity of O(|V|*|E|).</p> <p>It overcomes Dijkstra\u2019s shortcoming of no negative weights allowed.</p> <p>But if only positive weights are present Dijkstra is generally preferable.</p> <p>If the graph is dense and we have |E| in the order of |V|\u00b2, then this algorithm gives complexity of O(|V|\u00b3) like Floyd-Warshall but doesn\u2019t give as much information.</p> <p>However, with smaller number of edges and negative weights, this algorithm can be very useful.</p> <p>Bonus Tip:</p> <p>You can detect negative cycle using the Bellman-Ford algorithm!</p> <p>Once you do the bellman ford algorithm,for each edge from u to v check if distance[u]+cost[u][v]&lt;distance[v]. If it is true for any edge, then there is a negative cycle present.</p> <p>The reason is with |V|-1 iterations you get the minimum length path from to all vertices as long as there are no negative cycles. Now if the distance reduces, then it is because of a negative cycle.</p> <p>That was an introduction to a few popular shortest path algorithms. Hope you found it insightful.</p>"}]}